# =====================================================
# Memory System Configuration Template
# 记忆系统配置模板
# =====================================================
#
# SECURITY NOTICE / 安全提示:
# - Copy this file to .env and fill in your actual API keys
# - Never commit .env file to version control
# - Keep your API keys secure and private
# - 将此文件复制为.env并填入您的实际API密钥
# - 永远不要将.env文件提交到版本控制
# - 保护好您的API密钥安全
#
# SETUP INSTRUCTIONS / 设置说明:
# 1. cp env.template .env
# 2. Edit .env with your actual values
# 3. The system will automatically load these values
# =====================================================


# ===================
# LLM Configuration / LLM配置
# ===================

LLM_PROVIDER=openai
# evaluation 请用 openai/gpt-4.1-mini 以保证结果可复现性，demo 可使用 x-ai/grok-4-fast 平衡速度/成本/效果
LLM_MODEL=x-ai/grok-4-fast 
LLM_BASE_URL=https://openrouter.ai/api/v1
LLM_API_KEY=sk-or-v1-xxxx
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=32768
# openrouter/其他的供应商设置，默认为 default，用 openrouter 的 qwen3 时建议设置为 cerebras
# LLM_OPENROUTER_PROVIDER=cerebras

# ===================
# Vectorize (Embedding) Service Configuration
# ===================

# ---- Primary Vectorize Provider ----
# Provider type: vllm (self-deployed), deepinfra (commercial API)
VECTORIZE_PROVIDER=vllm

# API key for primary provider (use "EMPTY" if not required for vllm service)
VECTORIZE_API_KEY=EMPTY

# Base URL for primary provider
# vLLM service example: http://localhost:8000/v1
# DeepInfra example: https://api.deepinfra.com/v1/openai
VECTORIZE_BASE_URL=http://localhost:8000/v1

# Model name (shared by both primary and fallback providers)
VECTORIZE_MODEL=Qwen/Qwen3-Embedding-4B

# ---- Fallback Vectorize Provider (Optional) ----
# Fallback provider type: vllm, deepinfra, or none (to disable fallback)
# Note: Fallback will be disabled if provider is "none", base_url is empty, 
#       or api_key is empty (for deepinfra provider)
VECTORIZE_FALLBACK_PROVIDER=deepinfra

# API key for fallback provider (required for deepinfra, optional for vllm)
VECTORIZE_FALLBACK_API_KEY=xxxxx

# Base URL for fallback provider (required if fallback is enabled)
VECTORIZE_FALLBACK_BASE_URL=https://api.deepinfra.com/v1/openai

# ===== Common Settings =====
VECTORIZE_TIMEOUT=30
VECTORIZE_MAX_RETRIES=3
VECTORIZE_BATCH_SIZE=10
VECTORIZE_MAX_CONCURRENT=5
VECTORIZE_ENCODING_FORMAT=float

# Vector dimensions for client-side truncation
# Set to 0 to disable truncation and use full model dimensions
# Qwen3-Embedding-4B: full 2560D (DeepInfra) or 3584D (vLLM), recommend truncate to 1024D
# Note: Always uses client-side truncation with L2 re-normalization
VECTORIZE_DIMENSIONS=1024


# ===================
# Rerank Service Configuration
# ===================

# ---- Primary Rerank Provider ----
# Provider type: vllm (self-deployed), deepinfra (commercial API)
RERANK_PROVIDER=vllm

# API key for primary provider (use "EMPTY" if not required for vllm service)
RERANK_API_KEY=EMPTY

# Base URL for primary provider
# vLLM service example: http://localhost:12000/v1/rerank
# DeepInfra example: https://api.deepinfra.com/v1/inference
RERANK_BASE_URL=http://localhost:12000/v1/rerank

# Model name (shared by both primary and fallback providers)
RERANK_MODEL=Qwen/Qwen3-Reranker-4B

# ---- Fallback Rerank Provider (Optional) ----
# Fallback provider type: vllm, deepinfra, or none (to disable fallback)
# Note: Fallback will be disabled if provider is "none", base_url is empty,
#       or api_key is empty (for deepinfra provider)
RERANK_FALLBACK_PROVIDER=deepinfra

# API key for fallback provider (required for deepinfra, optional for vllm)
RERANK_FALLBACK_API_KEY=xxxxx

# Base URL for fallback provider (required if fallback is enabled)
RERANK_FALLBACK_BASE_URL=https://api.deepinfra.com/v1/inference

# ===== Common Settings =====
RERANK_TIMEOUT=30
RERANK_MAX_RETRIES=3
RERANK_BATCH_SIZE=10
RERANK_MAX_CONCURRENT=5


# ===================
# Redis Configuration / Redis配置
# ===================

REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=8
REDIS_SSL=false

# ===================
# MongoDB Configuration / MongoDB配置
# ===================

MONGODB_HOST=localhost
MONGODB_PORT=27017
MONGODB_USERNAME=admin
MONGODB_PASSWORD=memsys123
MONGODB_DATABASE=memsys
MONGODB_URI_PARAMS=socketTimeoutMS=15000&authSource=admin

# ===================
# Elasticsearch Configuration / Elasticsearch配置
# ===================

ES_HOSTS=http://localhost:19200
ES_USERNAME=
ES_PASSWORD=
ES_VERIFY_CERTS=false
SELF_ES_INDEX_NS=memsys

# ===================
# Milvus Configuration / Milvus向量数据库配置
# ===================

MILVUS_HOST=localhost
MILVUS_PORT=19530
SELF_MILVUS_COLLECTION_NS=memsys

# ===================
# API Server Configuration / API服务器配置
# ===================

# V3 API Base URL (用于 chat_with_memory.py 等客户端)
API_BASE_URL=http://localhost:8001

# ===================
# Environment & Logging / 环境与日志配置
# ===================

LOG_LEVEL=INFO
ENV=dev
PYTHONASYNCIODEBUG=1
MEMORY_LANGUAGE=en
